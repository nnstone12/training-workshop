{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a2ce51",
   "metadata": {},
   "source": [
    "#  Using the Planetary Variables Subscriptions API\n",
    "\n",
    "This Jupyter notebook goes over the useage of the Planetary Variables API. As a demonstration, the example of creating a subscription for Biomass Proxy and downloading some of the resulting TIFs is shown.\n",
    "\n",
    "For more detailed information, you can see the [Planetary Variables API user guide](https://docs.vandersat.com/data_access/api_user_guide.html#data-subscriptions).\n",
    "\n",
    "Updated Feb 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea672af9",
   "metadata": {},
   "source": [
    "# Part 0 - Getting set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc5afde",
   "metadata": {},
   "source": [
    "### 0.1 Install the necessary packages in your environment using pip and the requirements.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afdf24ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.prod.planet-labs.com/simple/\n",
      "Collecting requests_toolbelt\n",
      "  Using cached requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.1 in /opt/miniconda3/envs/pv_training/lib/python3.10/site-packages (from requests_toolbelt) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/pv_training/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.1->requests_toolbelt) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/pv_training/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.1->requests_toolbelt) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/miniconda3/envs/pv_training/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.1->requests_toolbelt) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/envs/pv_training/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.1->requests_toolbelt) (1.26.14)\n",
      "Installing collected packages: requests_toolbelt\n",
      "Successfully installed requests_toolbelt-0.10.1\n"
     ]
    }
   ],
   "source": [
    "#pip install -r requirements.txt\n",
    "!pip install requests_toolbelt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb951a3f",
   "metadata": {},
   "source": [
    "### 0.2 Import the necessary packages for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d73cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from typing import Iterator, List\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from requests import Response\n",
    "from requests_toolbelt.downloadutils import stream\n",
    "from requests_toolbelt.exceptions import StreamingError\n",
    "from requests_toolbelt.sessions import BaseUrlSession\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9925217b",
   "metadata": {},
   "source": [
    "### 0.3 API Functions that Run in the Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7229a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_hook(response: Response, *_args, **_kwargs):\n",
    "    \"\"\"Hook to get detailed error details from the response body.\"\"\"\n",
    "    if response.status_code >= 400:\n",
    "        logging.error(\n",
    "            f\"Error invoking API: url={response.url}; code={response.status_code}; \"\n",
    "            f\"reason={response.reason}; message={response.text}\"\n",
    "        )\n",
    "\n",
    "        exit(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c026623e",
   "metadata": {},
   "source": [
    "### 0.4 Enter your credentials for the Planetary Variables API\n",
    "It is recommended you do this via the use of environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aeac846",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTH = (os.getenv(\"VDS_USER\"), os.getenv(\"VDS_PASS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2a2fb",
   "metadata": {},
   "source": [
    "# Part 1 - Creating a new subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3c760",
   "metadata": {},
   "source": [
    "### 1.1 Specify the desired dates, product and geometry for your new subscription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b1e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full API name of the desired product, in this case for Biomass Proxy v2.0\n",
    "product = \"BIOMASS-PROXY_V2.0_10\"\n",
    "\n",
    "# between these dates your subscription will be active. the end_date can be in the future\n",
    "start_date = \"2022-03-15\"\n",
    "end_date = \"2022-09-01\"\n",
    "\n",
    "# what you would like the same of your data to be\n",
    "subscription_name = \"BP Test Subscription\"\n",
    "\n",
    "#path to the geometry of your field in .geojson format\n",
    "field_geom_path  = open(os.path.join(sys.path[0], \"Files_for_subscription_demo\", \"demo_field_1.geojson\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5627bfc9",
   "metadata": {},
   "source": [
    "### 1.2 Extract geometry out of geojson file\n",
    "This part extracts the geometry of the geojson file provided above so that it is in the correct format for the API to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88955f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf = gpd.read_file(field_geom_path)\n",
    "feature = json.loads(gpd.GeoSeries(geodf.geometry).to_json())\n",
    "feature_geometry = feature['features'][0]['geometry']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3e658",
   "metadata": {},
   "source": [
    "### 1.3 Configure the API session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85894c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    "    )\n",
    "session = BaseUrlSession(base_url=\"https://maps.vandersat.com/api/v2/\")\n",
    "session.hooks[\"response\"] = [response_hook]\n",
    "session.auth = AUTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb7972a",
   "metadata": {},
   "source": [
    "### 1.4 Create a new subscription\n",
    "\n",
    "Once run, you will see see from the response from the API that a subscription has been created which has a specific unique id (uuid). You should make a note of this uuid as you will need to use it to retreive the data you have requested.\n",
    "#### Note if you are requesting a non-field based product (e.g. soil water content or land surface temperature, the data dictionary must contain the extra \"api_requests_type\" argument\") - see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e5b0c09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 13:09:11,893 INFO Created subscription: {'uuid': '508942b1-8d17-41a1-9d56-ea988897f933', 'created_dt': '2023-02-08T21:09:11.858312', 'modified_dt': '2023-02-08T21:09:11.777664', 'cancelled_dt': None, 'area': 140657.03, 'api_name': 'BIOMASS-PROXY_V2.0_10', 'api_request_type': 'field-based', 'name': 'BP Test Subscription', 'start_date': '2022-03-15', 'end_date': '2022-09-01', 'geojson': {'type': 'MultiPolygon', 'coordinates': [[[[-2.561268812, 56.640136001], [-2.563668605, 56.641854195], [-2.561467612, 56.644949786], [-2.555162831, 56.643018592], [-2.561268812, 56.640136001]]]]}, 'arguments': None, 'http_notify': {'url': None}}\n"
     ]
    }
   ],
   "source": [
    "# build a dictionary of the parameters for the subscription which can be passed to the API\n",
    "\n",
    "data = {\n",
    "        \"name\": subscription_name,\n",
    "        \"api_name\": product,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"geojson\": feature_geometry,\n",
    "        }\n",
    "\n",
    "# IMPORTANT NOTE\n",
    "# if you are creating a subscription for a non-field based product (i.e. soil moisture or LST)\n",
    "# then you need to add this additional entry into the above dictionary:\n",
    "\n",
    "      #  \"arguments\": {\"format\": \"gtiff\", \"min_coverage\": 80}\n",
    "\n",
    "\n",
    "result = session.post(url=\"subscriptions\", json=data).json()\n",
    "logging.info(f\"Created subscription: {result}\")\n",
    "\n",
    "# (might take a short while before the response shows below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d47140",
   "metadata": {},
   "source": [
    "#### Important note: only once a subscription has been made will data processing for the Biomass Proxy begin. Depending on the size of the field, subscription length, and the current processing queue, you will typically have to wait 15 mins + before the data is ready for you to download."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5bf013",
   "metadata": {},
   "source": [
    "# Part 2 - Downloading data for an exisiting subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d392af0",
   "metadata": {},
   "source": [
    "### 2.1 Configure the API session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabb207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    "    )\n",
    "session = BaseUrlSession(base_url=\"https://maps.vandersat.com/api/v2/\")\n",
    "session.hooks[\"response\"] = [response_hook]\n",
    "session.auth = AUTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b3947",
   "metadata": {},
   "source": [
    "### 2.2 Functions needed to download via the API\n",
    "Ensure this block is ran before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "411ba6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(session: BaseUrlSession, urls: List[str], output_folder: str):\n",
    "    \"\"\"Save URL(s) using the Content-Disposition header's file name.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for url in urls:\n",
    "        # Find existing files: assume the Content-Disposition header\n",
    "        # uses the same name as the URL or at most adds a prefix, so a\n",
    "        # wildcard search suffices. A real application should not rely\n",
    "        # on that: use the fulfillment date or UUID to track handling.\n",
    "        name = url.split(\"/\")[-2]\n",
    "        existing = glob.glob(os.path.join(output_folder, f\"*{name}\"))\n",
    "        if existing:\n",
    "            logging.info(f\"Skipped existing file: name={existing[0]}; url={url}\")\n",
    "            continue\n",
    "\n",
    "        r = session.get(url=url, stream=True)\n",
    "        try:\n",
    "            filename = stream.stream_response_to_file(r, path=output_folder)\n",
    "            logging.info(f\"Downloaded file: name={filename}\")\n",
    "        except StreamingError as e:\n",
    "            logging.error(f\"Failed to download file; error={str(e)}; url={url}\")\n",
    "\n",
    "\n",
    "def get_all_pages(\n",
    "    session: BaseUrlSession, url: str, page_size: int = 50\n",
    ") -> Iterator[dict]:\n",
    "    \"\"\"Get a generator to fetch paginated API results page by page.\"\"\"\n",
    "    params = {\"page\": 1, \"limit\": page_size}\n",
    "    first_page = session.get(url=url, params=params).json()\n",
    "    yield first_page\n",
    "\n",
    "    page_count = math.ceil(first_page[\"total_items\"] / page_size)\n",
    "    for params[\"page\"] in range(2, page_count + 1):\n",
    "        next_page = session.get(url=url, params=params).json()\n",
    "        yield next_page\n",
    "        \n",
    "\n",
    "def handle_fulfillment(\n",
    "    session: BaseUrlSession, subscription_uuid: str, fulfillment: dict\n",
    ") -> bool:\n",
    "    \"\"\"Handle a single fulfillment, like from an HTTP notification.\"\"\"\n",
    "    if fulfillment[\"status\"] == \"Ready\":\n",
    "        output_folder = os.path.join(dir_for_data_download, subscription_uuid)\n",
    "\n",
    "        download_files(session, urls=fulfillment[\"files\"], output_folder=output_folder)\n",
    "\n",
    "    return fulfillment[\"status\"] in (\"Ready\", \"Error\")\n",
    "\n",
    "\n",
    "def get_subscription_fulfillments(\n",
    "    session: BaseUrlSession, subscription_uuid: str\n",
    ") -> bool:\n",
    "    \"\"\"Get fulfillments; not needed when using HTTP notifications.\"\"\"\n",
    "    url = f\"subscriptions/{subscription_uuid}/fulfillments\"\n",
    "    pending = None\n",
    "    for page in get_all_pages(session, url=url):\n",
    "        logging.info(f\"Fetched page of fulfillments: result={page}\")\n",
    "        for fulfillment in page[\"fulfillments\"]:\n",
    "            pending = pending or not handle_fulfillment(\n",
    "                session, subscription_uuid=subscription_uuid, fulfillment=fulfillment\n",
    "            )\n",
    "    # True if fulfillment(s) found and all were handled, False otherwise\n",
    "    return not pending\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f444777",
   "metadata": {},
   "source": [
    "### 2.3 Define which subscription you would like to download data for\n",
    "Since it takes some time for a Biomass Proxy subscription to be ready for download, here is one I made earlier for use here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bcab7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid = \"401d528b-053b-45ba-b3d1-3cecc5aeb650\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba7c8b",
   "metadata": {},
   "source": [
    "### 2.4 Download the tif files of your subscription \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a1b8f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 13:10:59,576 INFO Fetched page of fulfillments: result={'fulfillments': [{'uuid': '06e8f9a9-8d7b-4c92-827f-e171d2620f44', 'created_dt': '2023-02-01T16:35:48.032792', 'modified_dt': '2023-02-01T16:35:48.032792', 'date': '2022-05-01', 'http_notify_count': None, 'http_notify_status': None, 'last_http_notify_dt': None, 'last_http_notify_result': None, 'last_http_notify_message': None, 'files': ['https://maps.vandersat.com/api/v2/subscriptions/401d528b-053b-45ba-b3d1-3cecc5aeb650/fulfillments/06e8f9a9-8d7b-4c92-827f-e171d2620f44/data/2022-05-01.tif/download'], 'status': 'Ready', 'status_message': None}, {'uuid': '4416d48d-19f5-470b-95d2-e4ddb12f2e58', 'created_dt': '2023-02-01T16:35:48.093085', 'modified_dt': '2023-02-01T16:35:48.093085', 'date': '2022-05-02', 'http_notify_count': None, 'http_notify_status': None, 'last_http_notify_dt': None, 'last_http_notify_result': None, 'last_http_notify_message': None, 'files': ['https://maps.vandersat.com/api/v2/subscriptions/401d528b-053b-45ba-b3d1-3cecc5aeb650/fulfillments/4416d48d-19f5-470b-95d2-e4ddb12f2e58/data/2022-05-02.tif/download'], 'status': 'Ready', 'status_message': None}, {'uuid': 'bd480f1b-d765-4de0-94a0-c0eb3b936148', 'created_dt': '2023-02-01T16:35:48.121714', 'modified_dt': '2023-02-01T16:35:48.121714', 'date': '2022-05-03', 'http_notify_count': None, 'http_notify_status': None, 'last_http_notify_dt': None, 'last_http_notify_result': None, 'last_http_notify_message': None, 'files': ['https://maps.vandersat.com/api/v2/subscriptions/401d528b-053b-45ba-b3d1-3cecc5aeb650/fulfillments/bd480f1b-d765-4de0-94a0-c0eb3b936148/data/2022-05-03.tif/download'], 'status': 'Ready', 'status_message': None}, {'uuid': 'b5240921-0019-4870-9b87-5a4fd17de960', 'created_dt': '2023-02-01T16:35:48.170785', 'modified_dt': '2023-02-01T16:35:48.170785', 'date': '2022-05-04', 'http_notify_count': None, 'http_notify_status': None, 'last_http_notify_dt': None, 'last_http_notify_result': None, 'last_http_notify_message': None, 'files': ['https://maps.vandersat.com/api/v2/subscriptions/401d528b-053b-45ba-b3d1-3cecc5aeb650/fulfillments/b5240921-0019-4870-9b87-5a4fd17de960/data/2022-05-04.tif/download'], 'status': 'Ready', 'status_message': None}, {'uuid': '6ad553c1-ebaa-4431-b459-9d889c004675', 'created_dt': '2023-02-01T16:35:48.230344', 'modified_dt': '2023-02-01T16:35:48.230344', 'date': '2022-05-05', 'http_notify_count': None, 'http_notify_status': None, 'last_http_notify_dt': None, 'last_http_notify_result': None, 'last_http_notify_message': None, 'files': ['https://maps.vandersat.com/api/v2/subscriptions/401d528b-053b-45ba-b3d1-3cecc5aeb650/fulfillments/6ad553c1-ebaa-4431-b459-9d889c004675/data/2022-05-05.tif/download'], 'status': 'Ready', 'status_message': None}], 'total_items': 5}\n",
      "2023-02-08 13:10:59,817 INFO Downloaded file: name=/Users/octave.lepinard/Desktop/training_notebooks/401d528b-053b-45ba-b3d1-3cecc5aeb650/BIOMASS-PROXY_V2.0_10_401d528b-053b-45ba-b3d1-3cecc5aeb650_2022-05-01.tif\n",
      "2023-02-08 13:11:00,054 INFO Downloaded file: name=/Users/octave.lepinard/Desktop/training_notebooks/401d528b-053b-45ba-b3d1-3cecc5aeb650/BIOMASS-PROXY_V2.0_10_401d528b-053b-45ba-b3d1-3cecc5aeb650_2022-05-02.tif\n",
      "2023-02-08 13:11:00,311 INFO Downloaded file: name=/Users/octave.lepinard/Desktop/training_notebooks/401d528b-053b-45ba-b3d1-3cecc5aeb650/BIOMASS-PROXY_V2.0_10_401d528b-053b-45ba-b3d1-3cecc5aeb650_2022-05-03.tif\n",
      "2023-02-08 13:11:00,566 INFO Downloaded file: name=/Users/octave.lepinard/Desktop/training_notebooks/401d528b-053b-45ba-b3d1-3cecc5aeb650/BIOMASS-PROXY_V2.0_10_401d528b-053b-45ba-b3d1-3cecc5aeb650_2022-05-04.tif\n",
      "2023-02-08 13:11:00,925 INFO Downloaded file: name=/Users/octave.lepinard/Desktop/training_notebooks/401d528b-053b-45ba-b3d1-3cecc5aeb650/BIOMASS-PROXY_V2.0_10_401d528b-053b-45ba-b3d1-3cecc5aeb650_2022-05-05.tif\n"
     ]
    }
   ],
   "source": [
    "# the directory where the tiffs should be saved\n",
    "dir_for_data_download = \"/Users/octave.lepinard/Desktop/training_notebooks\"\n",
    "\n",
    "if not os.path.exists(dir_for_data_download):\n",
    "    os.mkdir(dir_for_data_download)\n",
    "\n",
    "while True:\n",
    "    # Get the fulfillments and download the resulting files\n",
    "    if get_subscription_fulfillments(session, subscription_uuid=uuid):\n",
    "        break\n",
    "    logging.info(\"Not done yet; sleeping 10 minutes\")\n",
    "    time.sleep(10 * 60)\n",
    "    \n",
    "session.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f5412",
   "metadata": {},
   "source": [
    "# Part 3 - Visualize a Subscription TIF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb00ad",
   "metadata": {},
   "source": [
    "### 3.0.1 Install required package - rasterio for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a863c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f58ac",
   "metadata": {},
   "source": [
    "### 3.0.2 Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3300a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48f278",
   "metadata": {},
   "source": [
    "### 3.1 Specify parameters for the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce277b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# where your tifs are saved\n",
    "path_to_saved_tifs = \"\"\n",
    "\n",
    "# the uuid of the subscription you would like to visualize\n",
    "uuid_to_visualize = \"401d528b-053b-45ba-b3d1-3cecc5aeb650\"\n",
    "\n",
    "# the product associated with this subscription that you will plot\n",
    "product = \"BIOMASS-PROXY_V2.0_10\"\n",
    "\n",
    "# the date you would like to visualize\n",
    "date_to_visualize = \"2022-05-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9838642f",
   "metadata": {},
   "source": [
    "### 3.2 Visualize a Single TIF with Colorbar using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.set_xlabel(\"Degrees Longitude\")\n",
    "ax.set_ylabel(\"Degrees Latitude\")\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "\n",
    "# open the tif file using Rasterio\n",
    "img = rasterio.open(path_to_tif)\n",
    "\n",
    "# plot the opened tif\n",
    "plot = rasterio.plot.show(img, \n",
    "            ax=ax, \n",
    "            cmap='Greens')\n",
    "\n",
    "\n",
    "retted = rasterio.plot.show(img, ax=ax, cmap='Greens')\n",
    "im = retted.get_images()[0]\n",
    "\n",
    "\n",
    "fig.colorbar(im, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191bc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
